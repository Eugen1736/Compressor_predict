import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
from sklearn.ensemble import IsolationForest

# --- helper functions -----------------------------------------------------
@st.cache_data(show_spinner=False)
def load_training_data(path: str = "brg_data.csv") -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—É—á–∞—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç."""
    return pd.read_csv(path)


@st.cache_data(show_spinner=False)
def build_model(train_df: pd.DataFrame):
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–∞—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –≤–µ—Ä–Ω—É—Ç—å –ø–æ—Ä–æ–≥."""
    sensor_columns = {
        'F—Ç–∫4': ['–ì–∞—Ä–º–æ–Ω–∏–∫–∞ –≤—Ä–∞—â. —Ç–µ–ª –∫–∞—á. –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞ –ø–µ—Ä–µ–¥–Ω–µ–π –æ–ø–æ—Ä—ã –ö–í–î', '–º–º/—Å'],
        'Fc4': ['–ì–∞—Ä–º–æ–Ω–∏–∫–∞ –≤—Ä–∞—â. —Å–µ–ø–∞—Ä–∞—Ç–æ—Ä–∞ –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞ –ø–µ—Ä–µ–¥–Ω–µ–π –æ–ø–æ—Ä—ã –ö–í–î', '–º–º/—Å'],
        'Fc2': ['–ì–∞—Ä–º. –≤—Ä–∞—â. —Å–µ–ø–∞—Ä. –ø–æ–¥—à. –∑–∞–¥–Ω–µ–π –æ–ø–æ—Ä—ã –ö–ù–î', '–º–º/—Å'],
        'Fc3': ['–ì–∞—Ä–º. –≤—Ä–∞—â. —Å–µ–ø–∞—Ä. –ø–æ–¥—à. –ø–µ—Ä–µ–¥–Ω–µ–π –æ–ø–æ—Ä—ã –ö–ù–î', '–º–º/—Å'],
    }

    X_train = train_df[list(sensor_columns.keys())]
    model = IsolationForest(n_estimators=400, contamination=0.05, random_state=42)
    model.fit(X_train)

    # –ø–æ—Ä–æ–≥ –¥–ª—è —Ä–∞–Ω–Ω–µ–≥–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –±–µ—Ä—ë–º 10-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å —Å–∫–æ—Ä-–∞ –Ω–∞ train
    threshold = pd.Series(model.decision_function(X_train)).quantile(0.1)

    return model, threshold, sensor_columns


def preprocess_test(df: pd.DataFrame) -> pd.DataFrame:
    """–°–¥–µ–ª–∞—Ç—å –∏–Ω–¥–µ–∫—Å–∞–º–∏ —Å—Ç–æ–ª–±–µ—Ü Date&time –∏ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ —Ñ–∏—á–∏ (–∫–∞–∫ –≤ –Ω–æ—É—Ç–±—É–∫–µ)."""
    df = df.copy()
    if 'Date&time' in df.columns:
        df['Date&time'] = pd.to_datetime(df['Date&time'])
        df = df.set_index('Date&time')
    else:
        # –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ—Å—Ç–æ —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –æ–Ω datetime
        df.index = pd.to_datetime(df.index)

    # –¥–æ–±–∞–≤–∏—Ç—å –¥—Ä–æ–±–Ω—ã–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Å–µ–Ω—Å–æ—Ä–æ–≤
    dt = df.index.to_series().diff().dt.total_seconds()
    for i in ['F—Ç–∫4', 'Fc4', 'Fc2', 'Fc3']:
        if i in df.columns:
            df[f'd{i}'] = df[i].diff() / dt
    return df


def analyze(df: pd.DataFrame, model: IsolationForest, threshold: float, sensor_columns: dict):
    """–î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∞–Ω–æ–º–∞–ª–∏–π –∏ –≤–µ—Ä–Ω—É—Ç—å –¥–∞—Ç—É –ø–µ—Ä–≤–æ–π –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω–æ–π –∞–Ω–æ–º–∞–ª–∏–∏."""
    df = df.copy()
    features = list(sensor_columns.keys())
    X = df[features]

    df['anomaly_score'] = model.decision_function(X)
    df['anomaly_flag'] = (model.predict(X) == -1).astype(int)

    window = 10
    df['anomaly_rate'] = df['anomaly_flag'].rolling(window=window).mean()
    df['anomaly_score_smooth'] = df['anomaly_score'].rolling(window=window).mean()
    df['smoothed_score_ewma'] = df['anomaly_score'].ewm(alpha=0.2).mean()

    df['early_warning'] = (df['anomaly_score_smooth'] < threshold).astype(int)
    N = 3
    df['confirmed_anomaly'] = (df['early_warning'].rolling(window=N).sum() == N).astype(int)

    first_true_anomaly = df['confirmed_anomaly'].idxmax()
    if first_true_anomaly is not pd.NaT and df.loc[first_true_anomaly, 'confirmed_anomaly'] == 1:
        return first_true_anomaly, df
    else:
        return None, df


# --- Streamlit UI ---------------------------------------------------------
# –∫–æ–Ω—Ñ–∏–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–∏–∫–æ–Ω–∫–∞ –∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ–∫–Ω–∞)
st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π", page_icon="üê±")

# —ç–∫—Ä–∞–Ω –∑–∞–≥—Ä—É–∑–∫–∏ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –∏ –∫–∞—Ä—Ç–∏–Ω–∫–æ–π –∫–æ—Ç–∞-—Ä–∞–±–æ—á–µ–≥–æ
st.title("–ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤ —Ç—É—Ä–±–∏–Ω—ã")
    
st.markdown(
    " –í –∫–∞—á–µ—Å—Ç–≤–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–æ—Å—Ç—É–ø–Ω—ã —Ñ–∞–π–ª—ã `CS_1.csv` –∏ `CS_2.csv`, –∞ —Ç–∞–∫–∂–µ –ª—é–±–æ–π –∑–∞–≥—Ä—É–∂–∞–µ–º—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º CSV."
)

# –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏
train_df = load_training_data()
model, threshold, sensor_columns = build_model(train_df)

st.sidebar.header("–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
choice = st.sidebar.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç:",
                            options=["CS_1.csv", "CS_2.csv", "Upload your own"])

test_df = None
if choice in ["CS_1.csv", "CS_2.csv"]:
    test_df = pd.read_csv(choice)
elif choice == "Upload your own":
    uploaded = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª", type=["csv"])
    if uploaded is not None:
        test_df = pd.read_csv(uploaded)

if test_df is None:
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤ sidebar –≤—ã–±–µ—Ä–∏—Ç–µ –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª.")
    st.stop()

# –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑
try:
    test_df = preprocess_test(test_df)
except Exception as e:
    st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {e}")
    st.stop()

first_anom, result_df = analyze(test_df, model, threshold, sensor_columns)

st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
if first_anom is not None:
    st.success(f"–ü–µ—Ä–≤–∞—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω–∞—è –∞–Ω–æ–º–∞–ª–∏—è: **{first_anom}**")
else:
    st.warning("–°—Ç–∞–±–∏–ª—å–Ω—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.")

st.write("–ü–æ—Ä–æ–≥ –¥–ª—è —Ä–∞–Ω–Ω–µ–≥–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è (10-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å –Ω–∞ train):", threshold)

# –≥—Ä–∞—Ñ–∏–∫
plot_df = result_df[['anomaly_score', 'anomaly_score_smooth']].copy()
# –¥–æ–±–∞–≤–∏–º —Å—Ç–æ–ª–±–µ—Ü —Å –ø–æ—Ä–æ–≥–æ–º, —á—Ç–æ–±—ã –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ
plot_df['threshold'] = threshold

# —Å—Ç—Ä–æ–∏–º Altair –≥—Ä–∞—Ñ–∏–∫, —á—Ç–æ–±—ã –∑–∞–¥–∞—Ç—å —Ü–≤–µ—Ç–∞
plot_df = plot_df.reset_index().melt(id_vars='Date&time', value_vars=['anomaly_score','anomaly_score_smooth','threshold'],
                                      var_name='metric', value_name='value')

chart = alt.Chart(plot_df).mark_line().encode(
    x='Date&time:T',
    y='value:Q',
    color=alt.Color('metric:N', scale=alt.Scale(domain=['anomaly_score','anomaly_score_smooth','threshold'],
                                              range=['blue','red','yellow'])),
)
st.altair_chart(chart, use_container_width=True)

# –ø–æ–∫–∞–∑–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É
with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"):  # –º–æ–∂–Ω–æ –ø—Ä–æ–∫—Ä—É—á–∏–≤–∞—Ç—å
    st.dataframe(result_df.head(200))

# –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
csv = result_df.to_csv().encode('utf-8')
st.download_button("–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∫ CSV", csv, "anomaly_results.csv", "text/csv")
